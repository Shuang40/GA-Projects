{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3 - Web APIs & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "To help counselor, schools and even parents to identify individual who potentially could hold suicidal thoughts. By analysing xisting posts in Reddit, we want to use multiple prediction models for identifying the best model to apply on text written by individual that could predict if this individual holds any suicidal thought, allowing immediate intervention and render support to these group of individuals.\n",
    "\n",
    "Beside aiming for accuracy of our prediction, we also want to target at the individual who falls under the depresssion category but somehow our prediction shows that this individal is in the suicidual category.\n",
    "\n",
    "Using Natural Language Processing, success is evaluated by the model has the highest score that combine both accuracy and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "Using Reddit's API, we will be scraping through the subreddits of 2 posts namely Depression and SuicideWatch.\\\n",
    "\n",
    "After examining the scrapped data, we see that the posts itself and the title both hold meaningful words for our analysis. So, we combine these 2 together and apply techniques to split the text into words, return them to their root form and also remove the stop words.\n",
    "1 interesting outcome was that we ended up having 1 empty post as all words are actually stops words. Since it became an empty post, we decided to drop that post for our analysis.\n",
    "\n",
    "Once we have cleaned the datasets, we start with putting it into our first modelling which is a simple combination of CountVectorizer and LogisticRegression. Comparing to the baseline accuracy of 51%, this basic model has a better score however it is overfitting.\n",
    "\n",
    "Using the same model, we added in pipelines and gridsearch to look for the best parameters and see if it will improve the score. The result shows that the variance was greatly reduced however, the accuracy needs to be improved.\n",
    "\n",
    "We run a function that uses 2 vectorizers (CountVectorizer and TfidVectorizer) with 3 models (LogisticRegression, MultinomialNB and KNeighborsClassifier. That gives a return of 6 results.\n",
    "As mentioned in the problem statement, we are looking out for individual who fall under the depression category but our prediction shows otherwise. This are the false negatives result we are looking at and thus apart from the accuracy, we will also be focusing on the recall score.\n",
    "\n",
    "\n",
    "### Contents:\n",
    "- [Import clean datasets](#Import-clean-datasets)\n",
    "- [Modelling](#Modelling)\n",
    "- [Evaluation](#Evaluation)\n",
    "- [Conclusion and Recommendation](#Conclusion-and-Recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eukar\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import regex as re\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "depress = pd.read_csv('datasets\\depress_clean.csv')\n",
    "suicide = pd.read_csv('datasets\\suicide_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(946, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext_title</th>\n",
       "      <th>is_suicide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>understand people reply immediately op invitat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>welcome r depression check post place take mom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>worst time dealing pain know new pain quite li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hey want share recent triumph thought killing ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>want say fuck life fuck life</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      selftext_title  is_suicide\n",
       "0  understand people reply immediately op invitat...           0\n",
       "1  welcome r depression check post place take mom...           0\n",
       "2  worst time dealing pain know new pain quite li...           0\n",
       "3  hey want share recent triumph thought killing ...           0\n",
       "4                       want say fuck life fuck life           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking out the shape and head of depress dataset\n",
    "\n",
    "print(depress.shape)\n",
    "depress.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(983, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext_title</th>\n",
       "      <th>is_suicide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seeing worrying increase pro suicide content s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>want recognise occasion please offering extra ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please get one comment upvote wanna feel alone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dear friend family lost long battle thought ta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first time decade getting help needed never la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      selftext_title  is_suicide\n",
       "0  seeing worrying increase pro suicide content s...           1\n",
       "1  want recognise occasion please offering extra ...           1\n",
       "2  please get one comment upvote wanna feel alone...           1\n",
       "3  dear friend family lost long battle thought ta...           1\n",
       "4  first time decade getting help needed never la...           1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking out the shape and head of suicide dataset\n",
    "\n",
    "print(suicide.shape)\n",
    "suicide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_suicide</th>\n",
       "      <th>selftext_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>understand people reply immediately op invitat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>welcome r depression check post place take mom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>worst time dealing pain know new pain quite li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>hey want share recent triumph thought killing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>want say fuck life fuck life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_suicide                                     selftext_title\n",
       "0           0  understand people reply immediately op invitat...\n",
       "1           0  welcome r depression check post place take mom...\n",
       "2           0  worst time dealing pain know new pain quite li...\n",
       "3           0  hey want share recent triumph thought killing ...\n",
       "4           0                       want say fuck life fuck life"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge both datasets together before assigning predictors and perform any train/test split.\n",
    "\n",
    "all_df = depress.append(suicide, sort=True)\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X will be the selftext_title column while y will be the is_suicide column\n",
    "\n",
    "X = all_df['selftext_title']\n",
    "y = all_df['is_suicide']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use both CountVectorizer and TfidVectorizer from scikit-learn to create features from the selftext_title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "# Keeping the stratify=y although our datasets are pretty balance\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.50959\n",
       "0    0.49041\n",
       "Name: is_suicide, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st, let's get our baseline accuracy\n",
    "# As 0.51 is higher than 0.49, 0.51 shall be the baseline accuracy \n",
    "\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8993 features in the model.\n",
      "Train score: 0.9889349930843707 \n",
      "Test score: 0.6728778467908902\n"
     ]
    }
   ],
   "source": [
    "# Basic CountVectorizer and LogisticRegression to get a simple first model\n",
    "\n",
    "cv_simple = CountVectorizer()\n",
    "X_train_cv = cv_simple.fit_transform(X_train)\n",
    "X_test_cv = cv_simple.transform(X_test)\n",
    "\n",
    "print('There are {} features in the model.'.format(len(cv_simple.get_feature_names())))\n",
    "\n",
    "lr_simple = LogisticRegression(solver='liblinear')\n",
    "lr_simple.fit(X_train_cv, y_train)\n",
    "score_train = lr_simple.score(X_train_cv, y_train)\n",
    "score_test = lr_simple.score(X_test_cv, y_test)\n",
    "\n",
    "print('Train score: {} \\nTest score: {}'.format(score_train, score_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score of the simple basic model of CountVectorizer and LogisticRegression is better than the baseline accuracy of 0.51.\\\n",
    "However, it seems to be overfitting with high variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>depression</th>\n",
       "      <td>-1.322843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depressed</th>\n",
       "      <td>-1.171122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advice</th>\n",
       "      <td>-1.070040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide</th>\n",
       "      <td>1.053179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>future</th>\n",
       "      <td>0.993349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numb</th>\n",
       "      <td>-0.976061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kill</th>\n",
       "      <td>0.965650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>-0.961023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wondering</th>\n",
       "      <td>-0.932214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holding</th>\n",
       "      <td>0.889355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friendship</th>\n",
       "      <td>-0.879591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pill</th>\n",
       "      <td>0.877442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>-0.860426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self</th>\n",
       "      <td>-0.856271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miserable</th>\n",
       "      <td>-0.844211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef\n",
       "features            \n",
       "depression -1.322843\n",
       "depressed  -1.171122\n",
       "advice     -1.070040\n",
       "suicide     1.053179\n",
       "future      0.993349\n",
       "numb       -0.976061\n",
       "kill        0.965650\n",
       "three      -0.961023\n",
       "wondering  -0.932214\n",
       "holding     0.889355\n",
       "friendship -0.879591\n",
       "pill        0.877442\n",
       "eat        -0.860426\n",
       "self       -0.856271\n",
       "miserable  -0.844211"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words that best predict the target based on the coefficients\n",
    "\n",
    "coef_names = cv_simple.get_feature_names()\n",
    "\n",
    "coef_df = pd.DataFrame ({\n",
    "    'features' : coef_names,\n",
    "    'coef' : lr_simple.coef_[0]\n",
    "}).set_index('features')\n",
    "\n",
    "coef_df.reindex(coef_df['coef'].abs().sort_values(ascending=False).index)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strangely to find depression/depressed are not lemmatized/stemmed. Need to further investigate on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will run CountVectorizer and LogisticRegression again but this time round adding in pipeline and grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipeline. Creating CountVectorizer and logReg\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(solver='liblinear'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:   12.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvec__max_features: 3000\n",
      "cvec__min_df: 2\n",
      "cvec__max_df: 0.9\n",
      "cvec__ngram_range: (1, 2)\n",
      "Train score: 0.665283540802213 \n",
      "Test score: 0.6563146997929606\n"
     ]
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [2500, 3000, 3500],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3, verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "score_train = gs.best_score_\n",
    "score_test = gs.score(X_test, y_test)\n",
    "best_params = gs.best_params_\n",
    "\n",
    "for i in pipe_params:\n",
    "    print('{}: {}'.format(i,best_params[i]))\n",
    "\n",
    "print('Train score: {} \\nTest score: {}'.format(score_train, score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>depression</th>\n",
       "      <td>-1.379363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wondering</th>\n",
       "      <td>-1.191003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide</th>\n",
       "      <td>1.182913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depressed</th>\n",
       "      <td>-1.177032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kill</th>\n",
       "      <td>1.124166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advice</th>\n",
       "      <td>-0.999078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>-0.981744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friendship</th>\n",
       "      <td>-0.978809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>-0.935213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miserable</th>\n",
       "      <td>-0.917823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pill</th>\n",
       "      <td>0.897187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boring</th>\n",
       "      <td>-0.889350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>future</th>\n",
       "      <td>0.888504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicidal</th>\n",
       "      <td>0.868631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>-0.840797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef\n",
       "features            \n",
       "depression -1.379363\n",
       "wondering  -1.191003\n",
       "suicide     1.182913\n",
       "depressed  -1.177032\n",
       "kill        1.124166\n",
       "advice     -0.999078\n",
       "normal     -0.981744\n",
       "friendship -0.978809\n",
       "eat        -0.935213\n",
       "miserable  -0.917823\n",
       "pill        0.897187\n",
       "boring     -0.889350\n",
       "future      0.888504\n",
       "suicidal    0.868631\n",
       "three      -0.840797"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look again at the words that best predict the target based on the coefficients\n",
    "\n",
    "coef_names = gs.best_estimator_.named_steps['cvec'].get_feature_names()\n",
    "coef_values = gs.best_estimator_.named_steps['lr'].coef_[0]\n",
    "\n",
    "coef_df = pd.DataFrame ({\n",
    "    'features' : coef_names,\n",
    "    'coef' : coef_values\n",
    "}).set_index('features')\n",
    "\n",
    "coef_df.reindex(coef_df['coef'].abs().sort_values(ascending=False).index)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The variance is greatly reduced suggest that the model is able to generalize well.\n",
    "- However, we need to improve on the score to achieve a higher accuracy on the prediction.\n",
    "- Changes are observed with the feature names. \n",
    "- Seems that we have more relevant/related key words appearing now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to ease the grid search of different parameters and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "def create_pipeline(items, use_params, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipe_items={\n",
    "        'cv': CountVectorizer(),\n",
    "        'tv': TfidfVectorizer(),\n",
    "        'lr': LogisticRegression(solver='liblinear'),\n",
    "        'mnb': MultinomialNB(),\n",
    "        'knn': KNeighborsClassifier()\n",
    "    }\n",
    "    \n",
    "    # Create param for each pipe_item\n",
    "    param_items = {\n",
    "        'cv': {'cv__max_features': [2000, 2500, 3000],\n",
    "               'cv__min_df': [2, 3],\n",
    "               'cv__max_df': [.85, .9],\n",
    "               'cv__ngram_range': [(1,1), (1,2)],\n",
    "              },\n",
    "        'tv': {'tv__max_features': [2000, 2500, 3000],\n",
    "               'tv__min_df': [2, 3],\n",
    "               'tv__max_df': [.85, .9],\n",
    "               'tv__ngram_range': [(1,1), (1,2)],\n",
    "              },\n",
    "        'lr': {'lr__C': [1, .05], # Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n",
    "              },\n",
    "        'mnb': {'mnb__alpha': [0.6, 0.8, 1.0]\n",
    "               },\n",
    "        'knn': {'knn__n_neighbors': [15,25,35,45,55]\n",
    "               }\n",
    "    }\n",
    "    \n",
    "    # Parameters for GridSearch\n",
    "    params = dict()\n",
    "    if use_params:\n",
    "        for i in items:\n",
    "            for p in param_items[i]:\n",
    "                params[p] = param_items[i][p]    \n",
    "    \n",
    "    # Pipeline\n",
    "    pipe_list = [(i,pipe_items[i]) for i in items]\n",
    "    print('Using:')\n",
    "    \n",
    "    for p in pipe_list:\n",
    "        print('\\t' + str(p[1]).split('(')[0])\n",
    "    pipe = Pipeline(pipe_list)\n",
    "    \n",
    "    # GridSearch \n",
    "    gs = GridSearchCV(pipe, param_grid=params, verbose=1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Print results\n",
    "    train_params = gs.best_params_\n",
    "    train_score = gs.score(X_train, y_train)\n",
    "    y_test_hat = gs.predict(X_test)\n",
    "    test_score = gs.score(X_test, y_test)\n",
    "    ROC_AUC = roc_auc_score(y_test, y_test_hat)\n",
    "    accuracy = accuracy_score(y_test, y_test_hat)\n",
    "    f1 = f1_score(y_test, y_test_hat)\n",
    "    recall = recall_score(y_test, y_test_hat)\n",
    "    precision = precision_score(y_test, y_test_hat)\n",
    "    \n",
    "    for r in train_params:\n",
    "        print('{}: {}'.format(r,train_params[r]))\n",
    "        \n",
    "    print('Train score: {}'.format(train_score))\n",
    "    print('Test score: {}'.format(test_score))\n",
    "    print('ROC_AUC score: {}'.format(ROC_AUC))\n",
    "    print('accuracy score: {}'.format(accuracy))\n",
    "    print('f1 score: {}'.format(f1))\n",
    "    print('recall score: {}'.format(recall))\n",
    "    print('precision score: {}'.format(precision))\n",
    "    print('')\n",
    "    \n",
    "    return train_score, test_score, ROC_AUC, accuracy, f1, recall, precision, y_test_hat, train_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will run the function to generate results of different vectorizer and model combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:\n",
      "\tCountVectorizer\n",
      "\tLogisticRegression\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eukar\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 144 out of 144 | elapsed:   25.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv__max_df: 0.85\n",
      "cv__max_features: 3000\n",
      "cv__min_df: 2\n",
      "cv__ngram_range: (1, 2)\n",
      "lr__C: 0.05\n",
      "Train score: 0.9080221300138313\n",
      "Test score: 0.6956521739130435\n",
      "ROC_AUC score: 0.6948903982710712\n",
      "accuracy score: 0.6956521739130435\n",
      "f1 score: 0.7111984282907662\n",
      "recall score: 0.7357723577235772\n",
      "precision score: 0.688212927756654\n",
      "\n",
      "Using:\n",
      "\tCountVectorizer\n",
      "\tMultinomialNB\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eukar\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 216 out of 216 | elapsed:   37.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv__max_df: 0.85\n",
      "cv__max_features: 2000\n",
      "cv__min_df: 3\n",
      "cv__ngram_range: (1, 1)\n",
      "mnb__alpha: 1.0\n",
      "Train score: 0.8485477178423236\n",
      "Test score: 0.7080745341614907\n",
      "ROC_AUC score: 0.7069311515899969\n",
      "accuracy score: 0.7080745341614907\n",
      "f1 score: 0.7283236994219653\n",
      "recall score: 0.7682926829268293\n",
      "precision score: 0.6923076923076923\n",
      "\n",
      "Using:\n",
      "\tCountVectorizer\n",
      "\tKNeighborsClassifier\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eukar\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv__max_df: 0.85\n",
      "cv__max_features: 2000\n",
      "cv__min_df: 2\n",
      "cv__ngram_range: (1, 1)\n",
      "knn__n_neighbors: 25\n",
      "Train score: 0.5663900414937759\n",
      "Test score: 0.5962732919254659\n",
      "ROC_AUC score: 0.5897653596789132\n",
      "accuracy score: 0.5962732919254659\n",
      "f1 score: 0.7031963470319634\n",
      "recall score: 0.9390243902439024\n",
      "precision score: 0.5620437956204379\n",
      "\n",
      "Using:\n",
      "\tTfidfVectorizer\n",
      "\tLogisticRegression\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eukar\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 144 out of 144 | elapsed:   24.5s finished\n",
      "C:\\Users\\eukar\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr__C: 1\n",
      "tv__max_df: 0.85\n",
      "tv__max_features: 2500\n",
      "tv__min_df: 2\n",
      "tv__ngram_range: (1, 1)\n",
      "Train score: 0.8838174273858921\n",
      "Test score: 0.7101449275362319\n",
      "ROC_AUC score: 0.7096583307605229\n",
      "accuracy score: 0.7101449275362319\n",
      "f1 score: 0.7211155378486055\n",
      "recall score: 0.7357723577235772\n",
      "precision score: 0.70703125\n",
      "\n",
      "Using:\n",
      "\tTfidfVectorizer\n",
      "\tMultinomialNB\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 216 out of 216 | elapsed:   34.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb__alpha: 0.8\n",
      "tv__max_df: 0.85\n",
      "tv__max_features: 2000\n",
      "tv__min_df: 2\n",
      "tv__ngram_range: (1, 1)\n",
      "Train score: 0.8817427385892116\n",
      "Test score: 0.7246376811594203\n",
      "ROC_AUC score: 0.7235000514562108\n",
      "accuracy score: 0.7246376811594203\n",
      "f1 score: 0.74373795761079\n",
      "recall score: 0.7845528455284553\n",
      "precision score: 0.706959706959707\n",
      "\n",
      "Using:\n",
      "\tTfidfVectorizer\n",
      "\tKNeighborsClassifier\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eukar\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn__n_neighbors: 15\n",
      "tv__max_df: 0.85\n",
      "tv__max_features: 3000\n",
      "tv__min_df: 2\n",
      "tv__ngram_range: (1, 1)\n",
      "Train score: 0.6964038727524204\n",
      "Test score: 0.660455486542443\n",
      "ROC_AUC score: 0.6594113409488525\n",
      "accuracy score: 0.660455486542443\n",
      "f1 score: 0.682170542635659\n",
      "recall score: 0.7154471544715447\n",
      "precision score: 0.6518518518518519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_params = True\n",
    "vects = ['cv', 'tv']\n",
    "models = ['lr', 'mnb', 'knn']\n",
    "\n",
    "model_soln = {}\n",
    "index = 0\n",
    "for v in vects:\n",
    "    for m in models:\n",
    "        index += 1\n",
    "        pipe_items = [v]\n",
    "        pipe_items.append(m)\n",
    "        [train_score, test_score, ROC_AUC, accuracy, f1, recall, precision, y_test_hat, best_params] = create_pipeline(pipe_items, use_params, X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        model_soln[index] = {'vectorizer': v, 'model': m, 'train_score': train_score, 'test_score': test_score,\n",
    "                             'ROC_AUC score' : ROC_AUC, 'accuracy': accuracy, 'f1_score': f1, 'recall_score': recall, \n",
    "                             'precision_score': precision, 'y_test_hat': y_test_hat, 'best_params': best_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the results together for comparison and selection of the best solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vectorizer</th>\n",
       "      <td>cv</td>\n",
       "      <td>cv</td>\n",
       "      <td>cv</td>\n",
       "      <td>tv</td>\n",
       "      <td>tv</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>lr</td>\n",
       "      <td>mnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>lr</td>\n",
       "      <td>mnb</td>\n",
       "      <td>knn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.908022</td>\n",
       "      <td>0.848548</td>\n",
       "      <td>0.56639</td>\n",
       "      <td>0.883817</td>\n",
       "      <td>0.881743</td>\n",
       "      <td>0.696404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.708075</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.660455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC_AUC score</th>\n",
       "      <td>0.69489</td>\n",
       "      <td>0.706931</td>\n",
       "      <td>0.589765</td>\n",
       "      <td>0.709658</td>\n",
       "      <td>0.7235</td>\n",
       "      <td>0.659411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.708075</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.660455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.711198</td>\n",
       "      <td>0.728324</td>\n",
       "      <td>0.703196</td>\n",
       "      <td>0.721116</td>\n",
       "      <td>0.743738</td>\n",
       "      <td>0.682171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score</th>\n",
       "      <td>0.735772</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.735772</td>\n",
       "      <td>0.784553</td>\n",
       "      <td>0.715447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score</th>\n",
       "      <td>0.688213</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.562044</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>0.70696</td>\n",
       "      <td>0.651852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_params</th>\n",
       "      <td>{'cv__max_df': 0.85, 'cv__max_features': 3000,...</td>\n",
       "      <td>{'cv__max_df': 0.85, 'cv__max_features': 2000,...</td>\n",
       "      <td>{'cv__max_df': 0.85, 'cv__max_features': 2000,...</td>\n",
       "      <td>{'lr__C': 1, 'tv__max_df': 0.85, 'tv__max_feat...</td>\n",
       "      <td>{'mnb__alpha': 0.8, 'tv__max_df': 0.85, 'tv__m...</td>\n",
       "      <td>{'knn__n_neighbors': 15, 'tv__max_df': 0.85, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 1  \\\n",
       "vectorizer                                                      cv   \n",
       "model                                                           lr   \n",
       "train_score                                               0.908022   \n",
       "test_score                                                0.695652   \n",
       "ROC_AUC score                                              0.69489   \n",
       "accuracy                                                  0.695652   \n",
       "f1_score                                                  0.711198   \n",
       "recall_score                                              0.735772   \n",
       "precision_score                                           0.688213   \n",
       "best_params      {'cv__max_df': 0.85, 'cv__max_features': 3000,...   \n",
       "\n",
       "                                                                 2  \\\n",
       "vectorizer                                                      cv   \n",
       "model                                                          mnb   \n",
       "train_score                                               0.848548   \n",
       "test_score                                                0.708075   \n",
       "ROC_AUC score                                             0.706931   \n",
       "accuracy                                                  0.708075   \n",
       "f1_score                                                  0.728324   \n",
       "recall_score                                              0.768293   \n",
       "precision_score                                           0.692308   \n",
       "best_params      {'cv__max_df': 0.85, 'cv__max_features': 2000,...   \n",
       "\n",
       "                                                                 3  \\\n",
       "vectorizer                                                      cv   \n",
       "model                                                          knn   \n",
       "train_score                                                0.56639   \n",
       "test_score                                                0.596273   \n",
       "ROC_AUC score                                             0.589765   \n",
       "accuracy                                                  0.596273   \n",
       "f1_score                                                  0.703196   \n",
       "recall_score                                              0.939024   \n",
       "precision_score                                           0.562044   \n",
       "best_params      {'cv__max_df': 0.85, 'cv__max_features': 2000,...   \n",
       "\n",
       "                                                                 4  \\\n",
       "vectorizer                                                      tv   \n",
       "model                                                           lr   \n",
       "train_score                                               0.883817   \n",
       "test_score                                                0.710145   \n",
       "ROC_AUC score                                             0.709658   \n",
       "accuracy                                                  0.710145   \n",
       "f1_score                                                  0.721116   \n",
       "recall_score                                              0.735772   \n",
       "precision_score                                           0.707031   \n",
       "best_params      {'lr__C': 1, 'tv__max_df': 0.85, 'tv__max_feat...   \n",
       "\n",
       "                                                                 5  \\\n",
       "vectorizer                                                      tv   \n",
       "model                                                          mnb   \n",
       "train_score                                               0.881743   \n",
       "test_score                                                0.724638   \n",
       "ROC_AUC score                                               0.7235   \n",
       "accuracy                                                  0.724638   \n",
       "f1_score                                                  0.743738   \n",
       "recall_score                                              0.784553   \n",
       "precision_score                                            0.70696   \n",
       "best_params      {'mnb__alpha': 0.8, 'tv__max_df': 0.85, 'tv__m...   \n",
       "\n",
       "                                                                 6  \n",
       "vectorizer                                                      tv  \n",
       "model                                                          knn  \n",
       "train_score                                               0.696404  \n",
       "test_score                                                0.660455  \n",
       "ROC_AUC score                                             0.659411  \n",
       "accuracy                                                  0.660455  \n",
       "f1_score                                                  0.682171  \n",
       "recall_score                                              0.715447  \n",
       "precision_score                                           0.651852  \n",
       "best_params      {'knn__n_neighbors': 15, 'tv__max_df': 0.85, '...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_solns = pd.DataFrame(model_soln)\n",
    "df_solns.loc[['vectorizer','model','train_score','test_score','ROC_AUC score','accuracy','f1_score',\n",
    "              'recall_score','precision_score', 'best_params'],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`True negatives`: Predict depression ; depression\\\n",
    "`False positives`: Predict suicide ; depression\\\n",
    "`False negatives`: Predict depression ; suicide\\\n",
    "`True positives`: Predict suicide ; suicide\\\n",
    "While we want ensure we have good prediction of suicide cases, we also need to be able to capture the `false negatives` cases where the predictions indicate depression but turn out to be suicidal.\n",
    "Thus, we will compare recall score and pick the best model.\\\n",
    "\\\n",
    "That being said, thou model 3 (CountVectorizer and KNN) return the highest recall score among all the models, the accuracy was rather low (although still better than baseline accuracy of 51%) which should be our 1st priority. Therefore, I won't be selecting this model.\n",
    "Instead, I will be aiming at model 5 (TfidVectorizer and Multinomial). It has the highest accuracy score (72%) yet having a relative high recall (rank 2nd at 78%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating bar graph to illustrate accuracy and recall score.\n",
    "\n",
    "transposed_df = df_solns.T # transposed dataframe\n",
    "transposed_df['index']=[1,2,3,4,5,6] # insert 1 more column named index\n",
    "\n",
    "# Using pd.melt to unpivot the DataFrame from wide format to long format\n",
    "barplot_df = pd.melt(transposed_df, id_vars=['index'], value_vars=['accuracy','recall_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 331,
       "width": 497
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to barplot using seaborn\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "sns.barplot(x='index', y='value', hue='variable', data=barplot_df, palette=\"YlOrRd\")\n",
    "\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('classification')\n",
    "plt.title('accuracy vs recall score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2000 features in the model.\n",
      "Train score: 0.8817427385892116 \n",
      "Test score: 0.7246376811594203\n",
      "accuracy: 0.7246376811594203\n",
      "recall: 0.7845528455284553\n"
     ]
    }
   ],
   "source": [
    "# Final model selected: TfidVectorizer and Multinomial with the best_params\n",
    "\n",
    "tfvec = TfidfVectorizer(ngram_range=(1,1), max_df=0.85, min_df=2, max_features=2000)\n",
    "X_train_tfvec = tfvec.fit_transform(X_train)\n",
    "X_test_tfvec = tfvec.transform(X_test)\n",
    "\n",
    "print('There are {} features in the model.'.format(len(tfvec.get_feature_names())))\n",
    "\n",
    "mnb = MultinomialNB(alpha=0.8)\n",
    "model = mnb.fit(X_train_tfvec, y_train)\n",
    "train_tfvec_score = mnb.score(X_train_tfvec, y_train)\n",
    "test_tfvec_score = mnb.score(X_test_tfvec, y_test)\n",
    "predictions = model.predict(X_test_tfvec)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "\n",
    "print('Train score: {} \\nTest score: {}'.format(train_tfvec_score, test_tfvec_score))\n",
    "print('accuracy: {}'.format(accuracy))\n",
    "print('recall: {}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_values</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     true_values  pred_probs\n",
       "333            1           1\n",
       "918            1           1\n",
       "447            1           1\n",
       "217            0           0\n",
       "647            0           0\n",
       "..           ...         ...\n",
       "164            1           0\n",
       "689            1           1\n",
       "668            1           1\n",
       "600            1           1\n",
       "913            1           1\n",
       "\n",
       "[483 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a dataframe called pred_df that contains:\n",
    "# 1. The list of true values of our test set.\n",
    "# 2. The list of predicted probabilities based on our model.\n",
    "\n",
    "pred_proba = [i[1] for i in np.round(mnb.predict_proba(X_test_tfvec)).astype(int)]\n",
    "\n",
    "pred_df = pd.DataFrame({'true_values': y_test,\n",
    "                        'pred_probs':pred_proba})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 2 conditions for filtering\n",
    "\n",
    "cond1 = pred_df['pred_probs'] == 0\n",
    "cond2 = pred_df['true_values'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2)\n",
      "Percentage of False Negative over total y_test set: 11%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_values</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     true_values  pred_probs\n",
       "510            1           0\n",
       "139            1           0\n",
       "776            1           0\n",
       "748            1           0\n",
       "787            1           0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering the conditions to show only False Negatives results\n",
    "\n",
    "fn_df = pred_df[cond2 & cond1]\n",
    "\n",
    "print(fn_df.shape)\n",
    "print('Percentage of False Negative over total y_test set: {}%'.format(round(53/483*100)))\n",
    "fn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- The selected model that we use for prediction is a combination of TfidVectorizer and MultinomialNB.\n",
    "- The best parameters for TfidVectorizer are with 2000 features, max_df at 85%, min_df at 2 with ngram_range=(1,1).\n",
    "- Apply MultinomialNB model, it gives us a accuracy and recall score of 72% and 78% respectively.\n",
    "- And focusing on the False negative results, it represent an approx. 11% (53 out of 483).\n",
    "\n",
    "Given this result, not only we can predict individuals with suicidal thoughts, we are also able to pick up those who are probably in the depression phase but starts to exhibit suicidal thoughts. This allows immediate intervention to prevent any mishap plus sending support and help to the individual to overcome this period.\n",
    "\n",
    "Area of improvements:\n",
    "- Stopwords. Recalling we removed an empty post due to stopwords ('what should i do'). However, in this context, this whole text seems to suggest some signal sending from the individual. Thus, in my opinion, it is also critical to investigate further.\n",
    "- Lemmetization. During EDA, spotted words such as depressed and depression / suicide and suicidual were somehow not return to the basic form.\n",
    "- Overlapping words. The overlap words (naming a few examples: want, know, life, like, etc) seems to be borderline stop words. Words like want and know need to be pair with other words to make out some meaning. Maybe, we need to look into the n-gram paratemeters again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
